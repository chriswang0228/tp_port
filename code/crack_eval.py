# -*- coding: utf-8 -*-
"""tileseg_unet_code(peel) (5).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ip0UbtuhWs1Rrgww7nyiGZNtizJypDPF

# What is Semantic Segmentation?
Semantic segmentation refers to the process of linking each pixel in an image to a class label. These labels could include a person, car, flower, piece of furniture, etc., just to mention a few.
We can think of semantic segmentation as image classification at a pixel level. For example, in an image that has many cars, segmentation will label all the objects as car objects. However, a separate class of models known as instance segmentation is able to label the separate instances where an object appears in an image. This kind of segmentation can be very useful in applications that are used to count the number of objects, such as counting the amount of foot traffic in a mall.

# Please upvote the kernel if you found it insightful!

# Import Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms as T
import torchvision
import torch.nn.functional as F
from torch.autograd import Variable

from PIL import Image
import cv2
import albumentations as A

import time
import os
from tqdm.notebook import tqdm
from statistics import median
import random
import sys


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.manual_seed(0)
random.seed(0)
np.random.seed(0)


#IMAGE_PATH = '../dataset/road/test/img/'
#MASK_PATH = '../dataset/road/test/mask/'
#X_test = os.listdir(MASK_PATH)

IMAGE_PATH = '/home/chriswang/project/tp_port/dataset/road/full/img/'
MASK_PATH = '/home/chriswang/project/tp_port/dataset/road/full/mask/'
X_train, X_test = train_test_split(os.listdir(IMAGE_PATH), test_size=0.1, random_state=19)

class DroneTestDataset(Dataset):
    
    def __init__(self, img_path, mask_path, X, transform=None):
        self.img_path = img_path
        self.mask_path = mask_path
        self.X = X
        self.transform = transform
        
    def __len__(self):
        return len(self.X)
    
    def __getitem__(self, idx):
        img = cv2.imread(self.img_path + self.X[idx])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        label = np.array(cv2.imread(self.mask_path + self.X[idx][:-4]+'.png', 0))
        label[ label == 128 ] = 1
        label[ label == 255 ] = 2 
        if self.transform is not None:
            aug = self.transform(image=img, mask=label)
            img = Image.fromarray(aug['image'])
            mask = aug['mask']
        
        if self.transform is None:
            img = Image.fromarray(img)
        mask = torch.from_numpy(mask).long()
            
        return img, mask

height=480
width=480
t_test = A.Resize(height, width, interpolation=cv2.INTER_NEAREST)
n_classes=3

def predict_image_mask_miou(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):
    model.eval()
    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])
    image = t(image)
    model.to(device); image=image.to(device)
    mask = mask.to(device)
    with torch.no_grad():
        
        image = image.unsqueeze(0)
        mask = mask.unsqueeze(0)
        
        output = model(image)
        result=torch.argmax(output, dim=1).squeeze(0)
        result[result==1] = 0
        result[result==2] = 1

        pred_mask = result.contiguous().view(-1)
        mask = mask.contiguous().view(-1)

        iou_per_class = []
        for clas in range(0, n_classes): #loop per pixel class
            true_class = pred_mask == clas
            true_label = mask == clas

            if true_label.long().sum().item() == 0: #no exist label in this loop
                iou_per_class.append(np.nan)
            else:
                intersect = torch.logical_and(true_class, true_label).sum().float().item()
                union = torch.logical_or(true_class, true_label).sum().float().item()

                iou = (intersect + 1e-10) / (union +1e-10)
                iou_per_class.append(iou)
    return result, iou_per_class

iou_array=[]
std_array=[]
test_set = DroneTestDataset(IMAGE_PATH, MASK_PATH, X_test, transform=t_test)
iou_list0=[]
iou_list1=[]
iou_list2=[]
model=torch.load('/home/chriswang/project/tp_port/model_weight/triple_class/crack_UPP(TL)_merge.pt')
model.eval()


iou0=np.zeros(len(test_set))
for i,test in enumerate(test_set):
    iou0[i]=predict_image_mask_miou(model, test[0], test[1])[1][0]
iou_list0.append(iou0.mean())

iou1=np.zeros(len(test_set))
for i,test in enumerate(test_set):
    iou1[i]=predict_image_mask_miou(model, test[0], test[1])[1][1]
iou_list1.append(np.nanmean(iou1))

iou2=np.zeros(len(test_set))
for i,test in enumerate(test_set):
    iou2[i]=predict_image_mask_miou(model, test[0], test[1])[1][2]
iou_list2.append(np.nanmean(iou2))

iou_array.append(iou_list0)
iou_array.append(iou_list1)
iou_array.append(iou_list2)
df = pd.DataFrame(np.array(iou_array))
df.to_csv('result_UPP(TL)_tri_tpport.csv')
